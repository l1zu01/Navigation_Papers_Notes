# Navigation_Papers_Notes

自用，总结入门 VLN 的心路历程（）

---

## 以下是 Robot Navigation 的论文和笔记整理：

### 🧭 Visual Exploration & Visual Navigation

| Year | Venue | Paper Title | Labels | Link |
|------|--------|--------------|---------|------|
| 2017 | arxiv | Unifying Map and Landmark Based Representations for Visual Navigation | 连续,PointNav,No prior exploration,Map-based memory | [📄 Notes] |
| 2018 | ICLR | SEMI-PARAMETRIC TOPOLOGICAL MEMORY FOR NAVIGATION | 离散,object goal,Pre-recorded exploration,Graph-based memory | [📄 Notes] |
| 2020 | ICLR | Learning to Explore Using Active Neural SLAM | 连续,PointNav,No prior exploration,Map-based memory | [📄 Notes](./Notes/ANSlam.md) |
| 2020 | ECCV | Occupancy Anticipation for Efficient Exploration and Navigation | 连续,PointNav,No prior exploration,Map-based memory | [📄 Notes] |
| 2020 | ECCV | Seeing the Un-Scene:Learning Amodal Semantic Maps for Room Navigation | 连续,PointNav,No prior exploration,Map-based memory | [📄 Notes] |
| 2023 | ICRA | Visual Language Maps for Robot Navigation | 连续,ObjectNav,Pre-recorded exploration,Map-based memory | [📄 Notes](./Notes/VLMaps.md) |

---

### 🗺️ VLN (Vision-Language Navigation)

| Year | Venue | Paper Title | Labels | Link |
|------|--------|--------------|---------|------|
| 2018 | CVPR | Vision-and-Language Navigation (Anderson et al.) | ... | [📄 Notes] |
| 2021 | ICCV | HAMT: Hierarchical Attention Memory Transformer for VLN | ... | [📄 Notes] |
| 2025 | arxiv | TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation | 离散,route goal,Pre-recorded exploration,Graph-based memory,Graph Planner | [📄 Notes](./Notes/TRAVEL.md) |
| 2025 | arxiv | FlexVLN: Flexible Adaptation for Diverse Vision-and-Language Navigation Tasks | 离散,object goal,No prior exploration,Foundation Model-based + Explicit Memories,LLM Planner | [📄 Notes](./Notes/FlexVLN.md) |
| 2025 | RA-L 25 | ApexNav: An Adaptive Exploration Strategy for Zero-Shot Object Navigation with Target-centric Semantic Fusion | 连续,object goal,No prior exploration,Map-based Memory(Explicit Memories) + Foundation Model-based 推理,VLM Agent | [📄 Notes](./Notes/ApexNav.md) |
| 2025 | arxiv | JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation | 连续,route goal,No prior exploration,Implicit Memory,VLM Agent | [📄 Notes](./Notes/JanusVLN.md) |
| 2025 | CoRL 25 | GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation | 连续,route goal,No prior exploration,...,Graph Planner | [📄 Notes](./Notes/GC-VLN.md) |
| 2025 | arxiv | LOVON: Legged Open-Vocabulary Object Navigator | 连续,object goal,No prior exploration,...,VLM Agent | [📄 Notes] |
| 2025 | CVPR 25 | Do Visual Imaginations Improve Vision-and-Language Navigation Agents? | 连续,route goal,No prior exploration,...,Graph Planner | [📄 Notes] |
| 2025 | arxiv | HA-VLN: A Benchmark for Human-Aware Navigation in Discrete-Continuous Environments with Dynamic Multi-Human Interactions, Real-World Validation, and an Open Leaderboard | Benchmark | [📄 Notes] |
| 2025 | CoRR 25 | Unseen from Seen: Rewriting Observation-Instruction Using Foundation Models for Augmenting Vision-Language Navigation | 连续,route goal,No prior exploration,...,Graph Planner | [📄 Notes] |
| 2025 | CVPR 25 | ForesightNav: Learning Scene Imagination for Efficient Exploration | 连续,route goal,No prior exploration,...,Graph Planner | [📄 Notes] |
| 2025 | arxiv | CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory | 连续,route goal,No prior exploration,...,Graph Planner | [📄 Notes] |
| 2025 | arxiv | BeliefMapNav: 3D Voxel-Based Belief Map for Zero-Shot Object Navigation | ... | [📄 Notes] |
| 2025 | arxiv | OctoNav: Towards Generalist Embodied Navigation | ... | [📄 Notes] |
| 2025 | arxiv | CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model | ... | [📄 Notes] |
| 2025 | arxiv | Streamvln: Streaming vision-and-language navigation via slowfast context modeling | ... | [📄 Notes] |
| 2025 | RSS | Uni-NaVid: A Video-based Vision-Language-Action Model for Unifying Embodied Navigation Tasks | ... | [📄 Notes] |
| 2025 | RSS | NaVILA: Legged Robot Vision-Language-Action Model for Navigation | ... | [📄 Notes] |
| 2025 | ICCV | Move to Understand a 3D Scene: Bridging Visual Grounding and Exploration for Efficient and Versatile Embodied Navigation	 | ... | [📄 Notes] |
| 2025 | ACL | NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM | ... | [📄 Notes] |
| 2025 | ICLR | Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel | ... | [📄 Notes] |
| 2025 | ICCV | SAME: Learning Generic Language-Guided Visual Navigation with State-Adaptive Mixture of Experts | ... | [📄 Notes] |
| 2025 | ICCV | NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments | ... | [📄 Notes] |
| 2025 | arxiv | EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation | ... | [📄 Notes] |
---

✅ **Tips**  
- `📄 Notes` 链接路径可以改成你在仓库的相对路径，例如 `./VLN/xxx.md`。  
- 你也可以为每个模块添加 emoji 或引用风格的描述，让版面更直观。  
- GitHub 会自动渲染 Markdown 表格与超链接。
 

